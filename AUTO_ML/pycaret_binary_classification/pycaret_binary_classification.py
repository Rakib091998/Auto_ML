# -*- coding: utf-8 -*-
"""Pycaret_Binary_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gsukmin5VPKFwpVav7wix6JQKb9nUAdf
"""

# Installing pycaret
!pip install pycaret

# Getting the Data
from pycaret.datasets import get_data
dataset = get_data('credit')

#check the shape of data
dataset.shape

#a sample of 1200 records has been withheld from the original dataset to be used for predictions
data = dataset.sample(frac=0.95, random_state=786).reset_index(drop=True)
data_unseen = dataset.drop(data.index).reset_index(drop=True)

print('Data for Modeling: ' + str(data.shape))
print('Unseen Data For Predictions: ' + str(data_unseen.shape))

"""# Setting up Environment in PyCaret"""

from pycaret.classification import *

exp_clf101 = setup(data = data, target = 'default', session_id=123)

"""# Comparing All Models"""

compare_models()

"""# Create a Model

### 1. Decision Tree Classifier
"""

dt = create_model('dt')

#trained model object is stored in the variable 'dt'. 
print(dt)

"""### 2. K Neighbors Classifier"""

knn = create_model('knn')

"""### 3. Random Forest Classifier"""

rf = create_model('rf')

"""### 4.Ridge Classifier"""

ridge = create_model('ridge')

"""# Tune a Model

### 1. Decision Tree Classifier
"""

tuned_dt = tune_model(dt) # pycaret version 2 code, for version 1 ('dt')

#tuned model object is stored in the variable 'tuned_dt'. 
print(tuned_dt)

"""### 2. K Neighbors Classifier"""

tuned_knn = tune_model(knn)

"""### 3. Random Forest Classifier"""

tuned_rf = tune_model(rf)

"""### 4. Ridge Classifier"""

tuned_ridge = tune_model(ridge)

"""***  Notice how the results after tuning have been improved:

     Decision Tree Classifier (Before: 0.7301 , After: 0.8183)
     K Neighbors Classifier (Before: 0.7505 , After: 0.7792)
     Random Forest Classifier (Before: 0.8093 , After: 0.8225)

# Plot a Model

### 1. AUC Plot
"""

plot_model(tuned_rf, plot = 'auc')

"""### 2. Precision-Recall Curve"""

plot_model(tuned_rf, plot = 'pr')

"""### 3. Feature Importance Plot"""

plot_model(tuned_rf, plot='feature')

"""### 4. Confusion Matrix"""

plot_model(tuned_rf, plot = 'confusion_matrix')

"""** Another way to analyze the performance of models is to use the   **evaluate_model**() function which displays a user interface for all of the **available** plots for a given model. It internally uses the plot_model() **function**."""

evaluate_model(tuned_rf)

"""# Predict on test / hold-out Sample"""

predict_model(tuned_rf);

"""# Finalize Model for Deployment"""

final_rf = finalize_model(tuned_rf)

#Final Random Forest model parameters for deployment
print(final_rf)

predict_model(final_rf);

### Notice how the AUC in final_rf has increased to 0.8189 from 0.7538, even though the model is the same. This is because the final_rf variable has been trained on the complete dataset including the test/hold-out set.

"""Predict on unseen data"""

unseen_predictions = predict_model(final_rf, data=data_unseen)
unseen_predictions.head()
# The Label and Score columns will be added onto the data_unseen set

"""# Saving the model"""

save_model(final_rf,'Final RF Model 08Feb2020')

"""# Loading the saved model"""

saved_final_rf = load_model('Final RF Model 08Feb2020')

"""Once the model is loaded in the environment, you can simply use it to predict on any new data using the same predict_model() function. Below we have applied the loaded model to predict the same data_unseen"""

new_prediction = predict_model(saved_final_rf, data=data_unseen)

new_prediction.head()

"""Notice that the results of unseen_predictions and new_prediction are identical"""